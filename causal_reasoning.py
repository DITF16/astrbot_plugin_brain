"""
ğŸ”— å› æœæ¨ç†å¼•æ“ (Causal Reasoning Engine)

å®ç°çœŸæ­£çš„å› æœæ¨ç†èƒ½åŠ›ï¼š
1. å› æœé“¾æœç´¢ (Causal Chain Search) â€” Aå¯¼è‡´Bå¯¼è‡´C
2. é€†å‘æ¨ç† (Backward Reasoning) â€” ä¸ºä»€ä¹ˆä¼šå‘ç”ŸX
3. å‡è®¾æ¨ç† (Hypothetical Reasoning) â€” å¦‚æœAä¼šæ€æ ·
4. è§£å†³æ–¹æ¡ˆæœç´¢ (Solution Search) â€” å¦‚ä½•è¾¾æˆX

æ ¸å¿ƒç®—æ³•ï¼š
- BFS/A* åœ¨å› æœå›¾ä¸Šæœç´¢è·¯å¾„
- è·¯å¾„ç½®ä¿¡åº¦è®¡ç®—
- å¤šè·¯å¾„ç»¼åˆ
"""

import torch
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Tuple, Set
from enum import Enum
from collections import deque
import heapq

from .cognitive_graph_model import CHANNEL_CAUSES, CHANNEL_IS_A, CHANNEL_HAS_PROP, CHANNEL_ASSOCIATED


class ReasoningType(Enum):
    """æ¨ç†ç±»å‹æšä¸¾"""
    WHY = "why"  # ä¸ºä»€ä¹ˆ X ä¼šå‘ç”Ÿï¼Ÿ
    HOW = "how"  # å¦‚ä½•è¾¾æˆ Xï¼Ÿ
    WHAT_IF = "what_if"  # å¦‚æœ X ä¼šæ€æ ·ï¼Ÿ
    PREDICT = "predict"  # X ä¼šå¯¼è‡´ä»€ä¹ˆï¼Ÿ
    EXPLAIN = "explain"  # è§£é‡Š X å’Œ Y çš„å…³ç³»
    NONE = "none"  # éå› æœé—®é¢˜


@dataclass
class CausalLink:
    """å› æœé“¾ä¸­çš„ä¸€ä¸ªç¯èŠ‚"""
    source: int  # æºæ¦‚å¿µç´¢å¼•
    target: int  # ç›®æ ‡æ¦‚å¿µç´¢å¼•
    source_word: str  # æºæ¦‚å¿µè¯
    target_word: str  # ç›®æ ‡æ¦‚å¿µè¯
    strength: float  # å› æœå¼ºåº¦ (0-1)
    channel: int  # æ¥æºé€šé“

    def __repr__(self):
        return f"{self.source_word} --({self.strength:.2f})--> {self.target_word}"


@dataclass
class CausalPath:
    """ä¸€æ¡å®Œæ•´çš„å› æœè·¯å¾„"""
    links: List[CausalLink] = field(default_factory=list)
    total_confidence: float = 0.0

    @property
    def length(self) -> int:
        return len(self.links)

    @property
    def start_word(self) -> Optional[str]:
        if self.links:
            return self.links[0].source_word
        return None

    @property
    def end_word(self) -> Optional[str]:
        if self.links:
            return self.links[-1].target_word
        return None

    def get_words(self) -> List[str]:
        """è·å–è·¯å¾„ä¸Šæ‰€æœ‰è¯"""
        if not self.links:
            return []
        words = [self.links[0].source_word]
        for link in self.links:
            words.append(link.target_word)
        return words

    def to_arrow_string(self) -> str:
        """è½¬ä¸ºç®­å¤´å­—ç¬¦ä¸²: A â†’ B â†’ C"""
        words = self.get_words()
        return " â†’ ".join(words)

    def __repr__(self):
        return f"CausalPath({self.to_arrow_string()}, conf={self.total_confidence:.2f})"


@dataclass
class ReasoningResult:
    """æ¨ç†ç»“æœ"""
    success: bool  # æ˜¯å¦æˆåŠŸæ¨ç†
    reasoning_type: ReasoningType  # æ¨ç†ç±»å‹
    query_concept: str  # æŸ¥è¯¢æ¦‚å¿µ
    target_concept: Optional[str] = None  # ç›®æ ‡æ¦‚å¿µ(å¦‚æœæœ‰)

    # æ¨ç†ç»“æœ
    primary_path: Optional[CausalPath] = None  # ä¸»è¦å› æœè·¯å¾„
    alternative_paths: List[CausalPath] = field(default_factory=list)  # å¤‡é€‰è·¯å¾„
    related_concepts: List[Tuple[str, float]] = field(default_factory=list)  # ç›¸å…³æ¦‚å¿µ

    # è‡ªç„¶è¯­è¨€è¾“å‡º
    explanation: str = ""  # è§£é‡Šæ–‡æœ¬
    keywords: List[str] = field(default_factory=list)  # å…³é”®è¯åˆ—è¡¨(ç»™è¡¨è¾¾ä¸­æ¢ç”¨)
    confidence: float = 0.0  # æ•´ä½“ç½®ä¿¡åº¦

    def __repr__(self):
        return f"ReasoningResult(type={self.reasoning_type.value}, success={self.success}, conf={self.confidence:.2f})"


class CausalReasoningEngine:
    """
    ğŸ§  å› æœæ¨ç†å¼•æ“

    æ ¸å¿ƒèŒè´£ï¼š
    1. æ£€æµ‹ç”¨æˆ·é—®é¢˜çš„ç±»å‹ (WHY/HOW/WHAT_IF/PREDICT)
    2. åœ¨å› æœå›¾ä¸Šæœç´¢ç›¸å…³è·¯å¾„
    3. ç»¼åˆå¤šæ¡è·¯å¾„ç”Ÿæˆè§£é‡Š
    4. è¾“å‡ºç»“æ„åŒ–çš„æ¨ç†ç»“æœ
    """

    # é—®é¢˜ç±»å‹å…³é”®è¯
    WHY_KEYWORDS = {"ä¸ºä»€ä¹ˆ", "ä¸ºå•¥", "æ€ä¹ˆä¼š", "ä½•ä»¥", "ç¼˜ä½•", "åŸå› ", "ä¸ºä½•"}
    HOW_KEYWORDS = {"æ€ä¹ˆ", "å¦‚ä½•", "æ€æ ·", "æ€ä¹ˆæ ·", "æ€ä¹ˆæ‰èƒ½", "æ€æ ·æ‰èƒ½", "æ–¹æ³•", "åŠæ³•"}
    WHAT_IF_KEYWORDS = {"å¦‚æœ", "å‡å¦‚", "è¦æ˜¯", "å€˜è‹¥", "ä¸‡ä¸€", "å‡è®¾"}
    PREDICT_KEYWORDS = {"ä¼šæ€æ ·", "ä¼šæ€ä¹ˆ", "ä¼šå¯¼è‡´", "ä¼šå¼•èµ·", "ä¼šé€ æˆ", "åæœ", "ç»“æœ"}

    def __init__(self, model, idx2word: dict, word2idx: dict):
        """
        Args:
            model: CognitiveGraphModel å®ä¾‹
            idx2word: ç´¢å¼•åˆ°è¯çš„æ˜ å°„
            word2idx: è¯åˆ°ç´¢å¼•çš„æ˜ å°„
        """
        self.model = model
        self.idx2word = idx2word
        self.word2idx = word2idx

        # æ¨ç†å‚æ•°
        self.max_search_depth = 6  # æœ€å¤§æœç´¢æ·±åº¦
        self.min_causal_strength = 0.1  # æœ€å°å› æœå¼ºåº¦é˜ˆå€¼
        self.max_paths = 5  # æœ€å¤šè¿”å›çš„è·¯å¾„æ•°
        self.beam_width = 10  # æŸæœç´¢å®½åº¦

    def detect_question_type(self, text: str) -> Tuple[ReasoningType, List[str]]:
        """
        æ£€æµ‹é—®é¢˜ç±»å‹å¹¶æå–å…³é”®æ¦‚å¿µ

        Returns:
            (é—®é¢˜ç±»å‹, å…³é”®æ¦‚å¿µåˆ—è¡¨)
        """
        text_lower = text.lower()

        # æ£€æµ‹é—®é¢˜ç±»å‹
        if any(kw in text for kw in self.WHY_KEYWORDS):
            q_type = ReasoningType.WHY
        elif any(kw in text for kw in self.WHAT_IF_KEYWORDS):
            q_type = ReasoningType.WHAT_IF
        elif any(kw in text for kw in self.PREDICT_KEYWORDS):
            q_type = ReasoningType.PREDICT
        elif any(kw in text for kw in self.HOW_KEYWORDS):
            q_type = ReasoningType.HOW
        else:
            q_type = ReasoningType.NONE

        # æå–å…³é”®æ¦‚å¿µ (ç®€åŒ–ç‰ˆ: ç§»é™¤é—®é¢˜è¯åçš„å‰©ä½™è¯)
        # å®é™…åº”è¯¥ç”¨åˆ†è¯ï¼Œè¿™é‡Œè°ƒç”¨è€…ä¼šä¼ å…¥å·²åˆ†è¯çš„indices
        concepts = []
        for kw_set in [self.WHY_KEYWORDS, self.HOW_KEYWORDS,
                       self.WHAT_IF_KEYWORDS, self.PREDICT_KEYWORDS]:
            for kw in kw_set:
                text = text.replace(kw, "")

        # æ¸…ç†åè¿”å›
        text = text.strip()
        if text:
            concepts.append(text)

        return q_type, concepts

    def reason(self,
               query_indices: List[int],
               query_text: str = "",
               reasoning_type: ReasoningType = None) -> ReasoningResult:
        """
        ä¸»æ¨ç†å…¥å£

        Args:
            query_indices: æŸ¥è¯¢æ¦‚å¿µçš„ç´¢å¼•åˆ—è¡¨
            query_text: åŸå§‹æŸ¥è¯¢æ–‡æœ¬ (ç”¨äºé—®é¢˜ç±»å‹æ£€æµ‹)
            reasoning_type: å¼ºåˆ¶æŒ‡å®šæ¨ç†ç±»å‹ (å¯é€‰)

        Returns:
            ReasoningResult
        """
        # 1. æ£€æµ‹é—®é¢˜ç±»å‹
        if reasoning_type is None:
            reasoning_type, _ = self.detect_question_type(query_text)

        # è¿‡æ»¤æœ‰æ•ˆç´¢å¼•
        valid_indices = [idx for idx in query_indices if idx > 1]
        if not valid_indices:
            return ReasoningResult(
                success=False,
                reasoning_type=reasoning_type,
                query_concept="",
                explanation="æ— æ³•è¯†åˆ«é—®é¢˜ä¸­çš„æ¦‚å¿µ"
            )

        # å–æœ€åä¸€ä¸ªæ¦‚å¿µä½œä¸ºä¸»è¦æŸ¥è¯¢å¯¹è±¡ (é€šå¸¸æ˜¯æ ¸å¿ƒæ¦‚å¿µ)
        main_idx = valid_indices[-1]
        main_word = self.idx2word.get(main_idx, "")

        # 2. æ ¹æ®ç±»å‹æ‰§è¡Œä¸åŒæ¨ç†
        if reasoning_type == ReasoningType.WHY:
            return self._reason_why(main_idx, main_word, valid_indices)
        elif reasoning_type == ReasoningType.HOW:
            return self._reason_how(main_idx, main_word, valid_indices)
        elif reasoning_type == ReasoningType.WHAT_IF:
            return self._reason_what_if(main_idx, main_word, valid_indices)
        elif reasoning_type == ReasoningType.PREDICT:
            return self._reason_predict(main_idx, main_word, valid_indices)
        else:
            # éå› æœé—®é¢˜ï¼Œè¿”å›ç›¸å…³è”æƒ³
            return self._reason_associate(main_idx, main_word, valid_indices)

    def _reason_why(self, concept_idx: int, concept_word: str,
                    context_indices: List[int]) -> ReasoningResult:
        """
        å›ç­”"ä¸ºä»€ä¹ˆ"ç±»é—®é¢˜
        æœç´¢å¯¼è‡´è¯¥æ¦‚å¿µçš„åŸå› é“¾
        """
        # é€†å‘æœç´¢: æ‰¾å¯¼è‡´ concept çš„åŸå› 
        antecedents = self.get_causal_antecedents(concept_idx, max_depth=self.max_search_depth)

        if not antecedents:
            # å°è¯•ç”¨è”æƒ³é€šé“
            related = self.get_associated_concepts(concept_idx, top_k=5)
            return ReasoningResult(
                success=False,
                reasoning_type=ReasoningType.WHY,
                query_concept=concept_word,
                related_concepts=related,
                explanation=f"æˆ‘è¿˜ä¸çŸ¥é“ä¸ºä»€ä¹ˆä¼š{concept_word}",
                keywords=[concept_word] + [w for w, _ in related[:3]],
                confidence=0.2
            )

        # æ„å»ºè§£é‡Š
        paths = antecedents[:self.max_paths]
        primary_path = paths[0] if paths else None

        # ç”Ÿæˆè‡ªç„¶è¯­è¨€è§£é‡Š
        explanation = self._generate_why_explanation(concept_word, paths)

        # æå–å…³é”®è¯
        keywords = self._extract_path_keywords(paths)

        # è®¡ç®—ç½®ä¿¡åº¦
        confidence = primary_path.total_confidence if primary_path else 0.0

        return ReasoningResult(
            success=True,
            reasoning_type=ReasoningType.WHY,
            query_concept=concept_word,
            primary_path=primary_path,
            alternative_paths=paths[1:],
            explanation=explanation,
            keywords=keywords,
            confidence=confidence
        )

    def _reason_how(self, goal_idx: int, goal_word: str,
                    context_indices: List[int]) -> ReasoningResult:
        """
        å›ç­”"å¦‚ä½•/æ€æ ·"ç±»é—®é¢˜
        é€†å‘æœç´¢è¾¾æˆç›®æ ‡çš„æ–¹æ³•
        """
        # é€†å‘æœç´¢: ä»€ä¹ˆèƒ½å¯¼è‡´ goal
        antecedents = self.get_causal_antecedents(goal_idx, max_depth=self.max_search_depth)

        if not antecedents:
            related = self.get_associated_concepts(goal_idx, top_k=5)
            return ReasoningResult(
                success=False,
                reasoning_type=ReasoningType.HOW,
                query_concept=goal_word,
                related_concepts=related,
                explanation=f"æˆ‘è¿˜ä¸çŸ¥é“å¦‚ä½•{goal_word}",
                keywords=[goal_word] + [w for w, _ in related[:3]],
                confidence=0.2
            )

        paths = antecedents[:self.max_paths]
        primary_path = paths[0] if paths else None

        explanation = self._generate_how_explanation(goal_word, paths)
        keywords = self._extract_path_keywords(paths)
        confidence = primary_path.total_confidence if primary_path else 0.0

        return ReasoningResult(
            success=True,
            reasoning_type=ReasoningType.HOW,
            query_concept=goal_word,
            primary_path=primary_path,
            alternative_paths=paths[1:],
            explanation=explanation,
            keywords=keywords,
            confidence=confidence
        )

    def _reason_what_if(self, condition_idx: int, condition_word: str,
                        context_indices: List[int]) -> ReasoningResult:
        """
        å›ç­”"å¦‚æœ...ä¼šæ€æ ·"ç±»é—®é¢˜
        æ­£å‘æœç´¢æ¡ä»¶çš„åæœ
        """
        # æ­£å‘æœç´¢: condition ä¼šå¯¼è‡´ä»€ä¹ˆ
        effects = self.get_causal_effects(condition_idx, max_depth=self.max_search_depth)

        if not effects:
            related = self.get_associated_concepts(condition_idx, top_k=5)
            return ReasoningResult(
                success=False,
                reasoning_type=ReasoningType.WHAT_IF,
                query_concept=condition_word,
                related_concepts=related,
                explanation=f"æˆ‘è¿˜ä¸ç¡®å®š{condition_word}ä¼šå¯¼è‡´ä»€ä¹ˆ",
                keywords=[condition_word] + [w for w, _ in related[:3]],
                confidence=0.2
            )

        paths = effects[:self.max_paths]
        primary_path = paths[0] if paths else None

        explanation = self._generate_what_if_explanation(condition_word, paths)
        keywords = self._extract_path_keywords(paths)
        confidence = primary_path.total_confidence if primary_path else 0.0

        return ReasoningResult(
            success=True,
            reasoning_type=ReasoningType.WHAT_IF,
            query_concept=condition_word,
            primary_path=primary_path,
            alternative_paths=paths[1:],
            explanation=explanation,
            keywords=keywords,
            confidence=confidence
        )

    def _reason_predict(self, action_idx: int, action_word: str,
                        context_indices: List[int]) -> ReasoningResult:
        """
        é¢„æµ‹è¡Œä¸ºçš„åæœ
        """
        # ä¸ what_if ç±»ä¼¼ï¼Œä½†æ›´å¼ºè°ƒæœ€ç»ˆç»“æœ
        return self._reason_what_if(action_idx, action_word, context_indices)

    def _reason_associate(self, concept_idx: int, concept_word: str,
                          context_indices: List[int]) -> ReasoningResult:
        """
        éå› æœé—®é¢˜ï¼Œè¿”å›è”æƒ³ç»“æœ
        """
        related = self.get_associated_concepts(concept_idx, top_k=10)

        return ReasoningResult(
            success=True,
            reasoning_type=ReasoningType.NONE,
            query_concept=concept_word,
            related_concepts=related,
            explanation="",
            keywords=[concept_word] + [w for w, _ in related[:5]],
            confidence=0.5
        )

    # =========================================================
    # ğŸ” å›¾æœç´¢ç®—æ³•
    # =========================================================

    def get_causal_effects(self, start_idx: int, max_depth: int = 5) -> List[CausalPath]:
        """
        è·å–æ¦‚å¿µçš„å› æœåæœ (æ­£å‘æœç´¢)
        ä½¿ç”¨ BFS + æŸæœç´¢

        Args:
            start_idx: èµ·å§‹æ¦‚å¿µç´¢å¼•
            max_depth: æœ€å¤§æœç´¢æ·±åº¦

        Returns:
            æŒ‰ç½®ä¿¡åº¦æ’åºçš„å› æœè·¯å¾„åˆ—è¡¨
        """
        if start_idx <= 1:
            return []

        cause_matrix = self.model.synapse_tensor[CHANNEL_CAUSES]
        device = cause_matrix.device

        # ä½¿ç”¨ä¼˜å…ˆé˜Ÿåˆ—è¿›è¡ŒæŸæœç´¢ (ç½®ä¿¡åº¦è¶Šé«˜ä¼˜å…ˆçº§è¶Šé«˜)
        # (è´Ÿç½®ä¿¡åº¦, è·¯å¾„)
        start_word = self.idx2word.get(start_idx, "")
        initial_path = CausalPath(links=[], total_confidence=1.0)

        # ä¼˜å…ˆé˜Ÿåˆ—: (-confidence, path_id, current_idx, path)
        # path_id ç”¨äºæ‰“ç ´ç½®ä¿¡åº¦ç›¸åŒæ—¶çš„é¡ºåº
        pq = [(-1.0, 0, start_idx, initial_path)]
        path_counter = 1

        visited_states = set()  # (current_idx, frozenset(path_indices))
        result_paths = []

        while pq and len(result_paths) < self.max_paths * 2:
            neg_conf, _, current_idx, current_path = heapq.heappop(pq)
            current_conf = -neg_conf

            # è·å–è·¯å¾„ä¸Šå·²è®¿é—®çš„èŠ‚ç‚¹
            path_indices = frozenset(link.target for link in current_path.links)
            state = (current_idx, path_indices)

            if state in visited_states:
                continue
            visited_states.add(state)

            # è·å–å½“å‰èŠ‚ç‚¹çš„å› æœåæœ
            effects = cause_matrix[current_idx]

            # æ‰¾åˆ°å¼ºåº¦è¶…è¿‡é˜ˆå€¼çš„åæœ
            strong_effects = (effects > self.min_causal_strength).nonzero(as_tuple=True)[0]

            if len(strong_effects) == 0 and current_path.length > 0:
                # åˆ°è¾¾ç»ˆç‚¹ï¼Œä¿å­˜è·¯å¾„
                result_paths.append(current_path)
                continue

            # æ‰©å±•è·¯å¾„
            for effect_idx in strong_effects.tolist():
                if effect_idx <= 1:  # è·³è¿‡ PAD, UNK
                    continue
                if effect_idx in path_indices:  # é¿å…ç¯
                    continue
                if effect_idx == start_idx:  # é¿å…å›åˆ°èµ·ç‚¹
                    continue

                effect_word = self.idx2word.get(effect_idx, "")
                strength = effects[effect_idx].item()

                # åˆ›å»ºæ–°é“¾æ¥
                source_word = self.idx2word.get(current_idx, "")
                new_link = CausalLink(
                    source=current_idx,
                    target=effect_idx,
                    source_word=source_word,
                    target_word=effect_word,
                    strength=strength,
                    channel=CHANNEL_CAUSES
                )

                # åˆ›å»ºæ–°è·¯å¾„
                new_path = CausalPath(
                    links=current_path.links + [new_link],
                    total_confidence=current_conf * min(strength, 1.0)
                )

                # å¦‚æœè¾¾åˆ°æ·±åº¦é™åˆ¶ï¼Œä¿å­˜è·¯å¾„
                if new_path.length >= max_depth:
                    result_paths.append(new_path)
                else:
                    # åŠ å…¥ä¼˜å…ˆé˜Ÿåˆ—
                    heapq.heappush(pq, (-new_path.total_confidence, path_counter, effect_idx, new_path))
                    path_counter += 1

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        result_paths.sort(key=lambda p: p.total_confidence, reverse=True)

        return result_paths[:self.max_paths]

    def get_causal_antecedents(self, end_idx: int, max_depth: int = 5) -> List[CausalPath]:
        """
        è·å–æ¦‚å¿µçš„å› æœå‰å›  (é€†å‘æœç´¢)
        ä½¿ç”¨è½¬ç½®çš„å› æœçŸ©é˜µè¿›è¡Œæœç´¢

        Args:
            end_idx: ç›®æ ‡æ¦‚å¿µç´¢å¼•
            max_depth: æœ€å¤§æœç´¢æ·±åº¦

        Returns:
            æŒ‰ç½®ä¿¡åº¦æ’åºçš„å› æœè·¯å¾„åˆ—è¡¨ (æ–¹å‘: åŸå›  â†’ ç»“æœ)
        """
        if end_idx <= 1:
            return []

        # è½¬ç½®å› æœçŸ©é˜µ: ä»"Aå¯¼è‡´B"å˜æˆ"Bè¢«Aå¯¼è‡´"
        cause_matrix = self.model.synapse_tensor[CHANNEL_CAUSES]
        reverse_matrix = cause_matrix.T  # è½¬ç½®

        end_word = self.idx2word.get(end_idx, "")
        initial_path = CausalPath(links=[], total_confidence=1.0)

        pq = [(-1.0, 0, end_idx, initial_path)]
        path_counter = 1

        visited_states = set()
        result_paths = []

        while pq and len(result_paths) < self.max_paths * 2:
            neg_conf, _, current_idx, current_path = heapq.heappop(pq)
            current_conf = -neg_conf

            path_indices = frozenset(link.source for link in current_path.links)
            state = (current_idx, path_indices)

            if state in visited_states:
                continue
            visited_states.add(state)

            # è·å–å¯¼è‡´å½“å‰èŠ‚ç‚¹çš„åŸå› 
            antecedents = reverse_matrix[current_idx]
            strong_antecedents = (antecedents > self.min_causal_strength).nonzero(as_tuple=True)[0]

            if len(strong_antecedents) == 0 and current_path.length > 0:
                # åˆ°è¾¾èµ·ç‚¹ï¼Œä¿å­˜è·¯å¾„ (éœ€è¦åè½¬)
                reversed_path = self._reverse_path(current_path)
                result_paths.append(reversed_path)
                continue

            for ante_idx in strong_antecedents.tolist():
                if ante_idx <= 1:
                    continue
                if ante_idx in path_indices:
                    continue
                if ante_idx == end_idx:
                    continue

                ante_word = self.idx2word.get(ante_idx, "")
                strength = antecedents[ante_idx].item()

                current_word = self.idx2word.get(current_idx, "")
                new_link = CausalLink(
                    source=ante_idx,
                    target=current_idx,
                    source_word=ante_word,
                    target_word=current_word,
                    strength=strength,
                    channel=CHANNEL_CAUSES
                )

                new_path = CausalPath(
                    links=[new_link] + current_path.links,
                    total_confidence=current_conf * min(strength, 1.0)
                )

                if new_path.length >= max_depth:
                    reversed_path = self._reverse_path(new_path)
                    result_paths.append(reversed_path)
                else:
                    heapq.heappush(pq, (-new_path.total_confidence, path_counter, ante_idx, new_path))
                    path_counter += 1

        result_paths.sort(key=lambda p: p.total_confidence, reverse=True)

        return result_paths[:self.max_paths]

    def search_causal_path(self, start_idx: int, end_idx: int,
                           max_depth: int = 6) -> Optional[CausalPath]:
        """
        æœç´¢ä¸¤ä¸ªæ¦‚å¿µä¹‹é—´çš„å› æœè·¯å¾„ (A* æœç´¢)

        Args:
            start_idx: èµ·å§‹æ¦‚å¿µç´¢å¼•
            end_idx: ç›®æ ‡æ¦‚å¿µç´¢å¼•
            max_depth: æœ€å¤§æœç´¢æ·±åº¦

        Returns:
            æ‰¾åˆ°çš„å› æœè·¯å¾„ï¼Œæˆ– None
        """
        if start_idx <= 1 or end_idx <= 1:
            return None
        if start_idx == end_idx:
            return None

        cause_matrix = self.model.synapse_tensor[CHANNEL_CAUSES]

        # A* æœç´¢: f(n) = g(n) + h(n)
        # g(n) = è´Ÿå¯¹æ•°ç½®ä¿¡åº¦ (ç´¯ç§¯ä»£ä»·)
        # h(n) = å¯å‘å¼ (è¿™é‡Œç®€åŒ–ä¸º0ï¼Œé€€åŒ–ä¸ºDijkstra)

        start_word = self.idx2word.get(start_idx, "")
        end_word = self.idx2word.get(end_idx, "")

        # (cost, counter, current_idx, path)
        pq = [(0.0, 0, start_idx, [])]
        path_counter = 1
        visited = set()

        while pq:
            cost, _, current_idx, path = heapq.heappop(pq)

            if current_idx == end_idx:
                # æ‰¾åˆ°äº†ï¼
                return CausalPath(
                    links=path,
                    total_confidence=self._cost_to_confidence(cost)
                )

            if current_idx in visited:
                continue
            visited.add(current_idx)

            if len(path) >= max_depth:
                continue

            effects = cause_matrix[current_idx]
            strong_effects = (effects > self.min_causal_strength).nonzero(as_tuple=True)[0]

            for effect_idx in strong_effects.tolist():
                if effect_idx <= 1 or effect_idx in visited:
                    continue

                strength = effects[effect_idx].item()
                edge_cost = -torch.log(torch.tensor(min(strength, 0.999))).item()

                current_word = self.idx2word.get(current_idx, "")
                effect_word = self.idx2word.get(effect_idx, "")

                new_link = CausalLink(
                    source=current_idx,
                    target=effect_idx,
                    source_word=current_word,
                    target_word=effect_word,
                    strength=strength,
                    channel=CHANNEL_CAUSES
                )

                new_cost = cost + edge_cost
                new_path = path + [new_link]

                heapq.heappush(pq, (new_cost, path_counter, effect_idx, new_path))
                path_counter += 1

        return None

    def get_associated_concepts(self, concept_idx: int, top_k: int = 10) -> List[Tuple[str, float]]:
        """
        è·å–å…³è”æ¦‚å¿µ (ä» ASSOCIATED é€šé“)

        Returns:
            [(word, strength), ...]
        """
        if concept_idx <= 1:
            return []

        assoc_matrix = self.model.synapse_tensor[CHANNEL_ASSOCIATED]
        weights = assoc_matrix[concept_idx]

        # è·å– top-k
        values, indices = torch.topk(weights, min(top_k + 2, len(weights)))

        results = []
        for val, idx in zip(values.tolist(), indices.tolist()):
            if idx <= 1:  # è·³è¿‡ PAD, UNK
                continue
            if idx == concept_idx:  # è·³è¿‡è‡ªå·±
                continue
            word = self.idx2word.get(idx, "")
            if word:
                results.append((word, val))

        return results[:top_k]

    # =========================================================
    # ğŸ“ è‡ªç„¶è¯­è¨€ç”Ÿæˆ
    # =========================================================

    def _generate_why_explanation(self, concept: str, paths: List[CausalPath]) -> str:
        """ç”Ÿæˆ"ä¸ºä»€ä¹ˆ"çš„è§£é‡Š"""
        if not paths:
            return f"æˆ‘è¿˜ä¸çŸ¥é“ä¸ºä»€ä¹ˆä¼š{concept}"

        explanations = []

        for i, path in enumerate(paths[:3]):
            if path.length == 0:
                continue

            words = path.get_words()
            if len(words) >= 2:
                cause_chain = " â†’ ".join(words)

                if i == 0:
                    explanations.append(f"å› ä¸º {words[0]}ï¼Œæ‰€ä»¥å¯¼è‡´äº† {concept}")
                    if len(words) > 2:
                        explanations.append(f"ï¼ˆå®Œæ•´å› æœé“¾ï¼š{cause_chain}ï¼‰")
                else:
                    explanations.append(f"å¦å¤–ï¼Œ{words[0]} ä¹Ÿå¯èƒ½å¯¼è‡´ {concept}")

        return "ã€‚".join(explanations) if explanations else f"æˆ‘è¿˜ä¸å¤ªæ¸…æ¥šä¸ºä»€ä¹ˆä¼š{concept}"

    def _generate_how_explanation(self, goal: str, paths: List[CausalPath]) -> str:
        """ç”Ÿæˆ"å¦‚ä½•"çš„è§£é‡Š"""
        if not paths:
            return f"æˆ‘è¿˜ä¸çŸ¥é“å¦‚ä½•{goal}"

        methods = []

        for path in paths[:3]:
            if path.length == 0:
                continue

            words = path.get_words()
            if words:
                # å–å› æœé“¾çš„èµ·ç‚¹ä½œä¸ºæ–¹æ³•
                method = words[0]
                methods.append(method)

        if not methods:
            return f"æˆ‘è¿˜ä¸çŸ¥é“å¦‚ä½•{goal}"

        if len(methods) == 1:
            return f"è¦{goal}çš„è¯ï¼Œå¯ä»¥è¯•è¯•{methods[0]}"
        else:
            method_str = "ã€".join(methods[:-1]) + f"æˆ–è€…{methods[-1]}"
            return f"è¦{goal}çš„è¯ï¼Œå¯ä»¥è¯•è¯•{method_str}"

    def _generate_what_if_explanation(self, condition: str, paths: List[CausalPath]) -> str:
        """ç”Ÿæˆ"å¦‚æœ"çš„è§£é‡Š"""
        if not paths:
            return f"æˆ‘è¿˜ä¸ç¡®å®š{condition}ä¼šå¯¼è‡´ä»€ä¹ˆ"

        effects = []

        for path in paths[:3]:
            if path.length == 0:
                continue

            words = path.get_words()
            if len(words) >= 2:
                # å–å› æœé“¾çš„ç»ˆç‚¹ä½œä¸ºç»“æœ
                effect = words[-1]
                effects.append(effect)

        if not effects:
            return f"æˆ‘è¿˜ä¸ç¡®å®š{condition}ä¼šå¯¼è‡´ä»€ä¹ˆ"

        if len(effects) == 1:
            return f"å¦‚æœ{condition}çš„è¯ï¼Œå¯èƒ½ä¼šå¯¼è‡´{effects[0]}"
        else:
            effect_str = "ã€".join(effects[:-1]) + f"ç”šè‡³{effects[-1]}"
            return f"å¦‚æœ{condition}çš„è¯ï¼Œå¯èƒ½ä¼šå¯¼è‡´{effect_str}"

    def _extract_path_keywords(self, paths: List[CausalPath]) -> List[str]:
        """ä»è·¯å¾„ä¸­æå–å…³é”®è¯"""
        keywords = []
        seen = set()

        for path in paths:
            for word in path.get_words():
                if word and word not in seen:
                    keywords.append(word)
                    seen.add(word)

        return keywords[:10]

    def _reverse_path(self, path: CausalPath) -> CausalPath:
        """åè½¬è·¯å¾„æ–¹å‘"""
        # å¯¹äºé€†å‘æœç´¢ï¼Œéœ€è¦åè½¬é“¾æ¥çš„æ–¹å‘
        return CausalPath(
            links=path.links,  # é“¾æ¥åœ¨æœç´¢æ—¶å·²ç»æ˜¯æ­£ç¡®æ–¹å‘
            total_confidence=path.total_confidence
        )

    def _cost_to_confidence(self, cost: float) -> float:
        """å°†ä»£ä»·è½¬æ¢ä¸ºç½®ä¿¡åº¦"""
        import math
        return math.exp(-cost)

    # =========================================================
    # ğŸ”§ è¾…åŠ©æ–¹æ³•
    # =========================================================

    def get_causal_strength(self, source_idx: int, target_idx: int) -> float:
        """è·å–ä¸¤ä¸ªæ¦‚å¿µä¹‹é—´çš„ç›´æ¥å› æœå¼ºåº¦"""
        if source_idx <= 1 or target_idx <= 1:
            return 0.0

        return self.model.synapse_tensor[CHANNEL_CAUSES, source_idx, target_idx].item()

    def get_causal_stats(self) -> Dict:
        """è·å–å› æœå›¾ç»Ÿè®¡ä¿¡æ¯"""
        cause_matrix = self.model.synapse_tensor[CHANNEL_CAUSES]

        # éé›¶è¿æ¥æ•°
        nonzero = (cause_matrix.abs() > self.min_causal_strength).sum().item()
        total = cause_matrix.numel()

        # å¹³å‡å¼ºåº¦
        mask = cause_matrix.abs() > self.min_causal_strength
        if mask.any():
            avg_strength = cause_matrix[mask].mean().item()
        else:
            avg_strength = 0.0

        # æœ€å¼ºè¿æ¥
        max_strength = cause_matrix.max().item()
        max_idx = cause_matrix.argmax().item()
        max_source = max_idx // cause_matrix.shape[1]
        max_target = max_idx % cause_matrix.shape[1]

        return {
            "total_connections": nonzero,
            "density": nonzero / total,
            "avg_strength": avg_strength,
            "max_strength": max_strength,
            "strongest_link": (
                self.idx2word.get(max_source, "?"),
                self.idx2word.get(max_target, "?")
            )
        }
