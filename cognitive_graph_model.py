import torch
import torch.nn as nn
import math


class CognitiveGraphModel(nn.Module):
    def __init__(self, vocab_size, embed_dim=256):
        super().__init__()

        self.vocab_size = vocab_size
        self.embed_dim = embed_dim

        # 1. é™æ€åŸºå› ï¼šè¯å‘é‡ (L0 æ„ŸçŸ¥å±‚)
        self.embeddings = nn.Embedding(vocab_size, embed_dim)

        # 2. åŠ¨æ€çªè§¦ï¼šå›¾è¿æ¥çŸ©é˜µ (å¯å­¦ä¹ å‚æ•°)
        # åˆå§‹åŒ–ä¸ºå•ä½çŸ©é˜µ + å¾®å¼±å™ªéŸ³
        # Trainer ä¼šè´Ÿè´£å¯¹è¿™ä¸ªçŸ©é˜µè¿›è¡Œ"èµ«å¸ƒæ›´æ–°"å’Œ"èƒ½é‡å½’ä¸€åŒ–"
        self.synapse_matrix = nn.Parameter(
            torch.eye(vocab_size) + torch.randn(vocab_size, vocab_size) * 0.01
        )

        # 3. åŠ¨æ€ç»éªŒï¼šè¯é¢‘ç»Ÿè®¡ (è®°å¿† Buffer)
        # ä½¿ç”¨ register_buffer ç¡®ä¿è¿™äº›ç»Ÿè®¡æ•°æ®éšæ¨¡å‹ä¿å­˜ï¼Œä½†ä¸éœ€è¦æ¢¯åº¦ä¸‹é™
        self.register_buffer("word_counts", torch.ones(vocab_size))
        self.register_buffer("total_experience", torch.tensor(float(vocab_size)))

    def get_attention_weights(self, input_indices):
        """
        è®¡ç®—"æƒŠè®¶åº¦"æƒé‡ (Dynamic Saliency)ã€‚
        åŸºäºéŸ¦ä¼¯-è´¹å¸Œçº³å®šå¾‹ï¼šè¶Šç½•è§çš„ä¸œè¥¿ï¼Œåˆºæ¿€å¼ºåº¦è¶Šå¤§ã€‚
        """
        counts = self.word_counts[input_indices]
        total = self.total_experience

        # IDF å˜ä½“å…¬å¼
        weights = torch.log(total + 1) / (torch.log(counts + 1) + 1e-6)

        # å½’ä¸€åŒ–é™åˆ¶ (0.1 ~ 3.0)
        weights = torch.clamp(weights * 0.5, min=0.1, max=3.0)

        return weights

    def learn_from_input(self, input_indices):
        """
        [åœ¨çº¿å­¦ä¹ ] æ›´æ–°ç»éªŒç»Ÿè®¡
        """
        # å±•å¹³å¹¶æ›´æ–°è®¡æ•°
        flat_indices = input_indices.view(-1)
        for idx in flat_indices:
            self.word_counts[idx] += 1
            self.total_experience += 1

    def forward(self, input_indices, steps=3):
        """
        å‰å‘ä¼ æ’­ï¼šè¾“å…¥è¯ç´¢å¼• -> æ¿€æ´»æ€ç»´å›¾è°± -> èƒ½é‡æ‰©æ•£
        """
        batch_size, seq_len = input_indices.shape

        # 1. è®¡ç®—åŠ¨æ€æƒé‡
        attn_weights = self.get_attention_weights(input_indices)

        # 2. æ³¨å…¥èƒ½é‡ (Injection)
        # å°†è¾“å…¥çš„è¯åœ¨å…¨è¯è¡¨ç©ºé—´ç‚¹äº®
        current_thought = torch.zeros(
            batch_size, self.vocab_size, device=input_indices.device
        )

        # æŠŠæƒé‡å€¼ä½œä¸ºèƒ½é‡æ³¨å…¥
        src = attn_weights
        current_thought.scatter_add_(1, input_indices, src)

        # 3. æ€ç»´æ‰©æ•£ (Diffusion)
        # è®©èƒ½é‡æ²¿ç€çªè§¦çŸ©é˜µæ¸¸èµ°
        for _ in range(steps):
            current_thought = torch.matmul(current_thought, self.synapse_matrix)
            current_thought = torch.relu(current_thought)  # æ¿€æ´»é˜ˆå€¼

        # 4. é¡ºä¾¿å­¦ä¹  (è®­ç»ƒæ¨¡å¼ä¸‹è‡ªåŠ¨æ›´æ–°ç»Ÿè®¡)
        if self.training:
            self.learn_from_input(input_indices)

        return current_thought

    def generate_reply(self, input_indices, max_len=20):
        """
        [ç”Ÿæˆæ¨¡å—] æ¦‚ç‡èƒ½é‡é‡‡æ · + è¿”å›æŠ‘åˆ¶ (Inhibition of Return)
        """
        self.eval()  # ç¡®ä¿ç”Ÿæˆæ—¶ä¸æ›´æ–°ç»Ÿè®¡

        # 1. äº§ç”Ÿæ„å¿µ (Thought Map)
        with torch.no_grad():
            thought_energy = self(input_indices, steps=3)

        # 2. åˆå§‹çŠ¶æ€è®¾ç½®
        # [æ ¸å¿ƒè¡¥ä¸] è¿”å›æŠ‘åˆ¶åˆå§‹åŒ–ï¼š
        # å°†è¾“å…¥é—®é¢˜é‡Œçš„è¯ç›´æ¥åŠ å…¥"å·²è®¿é—®"ï¼Œå¼ºè¿«æ¨¡å‹å‘å¤–å»¶å±•ï¼Œè€Œä¸æ˜¯å¤è¯»é—®é¢˜
        visited = set(input_indices[0].tolist())

        # 3. é€‰å–èµ·ç‚¹ (Seed Selection)
        # æˆ‘ä»¬è¦é¿å¼€å·²ç»é—®è¿‡çš„è¯
        start_energy = thought_energy[0].clone()
        for v in visited:
            start_energy[v] = -float("inf")  # å±è”½è¾“å…¥è¯

        # å¦‚æœå±è”½åæ²¡è¯äº†(æç½•è§)ï¼Œå°±éšä¾¿é€‰ä¸€ä¸ª
        if torch.max(start_energy) == -float("inf"):
            probs = torch.ones_like(start_energy)
        else:
            probs = torch.softmax(start_energy * 2.0, dim=0)

        current_idx = torch.multinomial(probs, 1).item()

        reply_indices = [current_idx]
        visited.add(current_idx)  # æ ‡è®°èµ·ç‚¹å·²è®¿é—®

        print(f"ğŸ—£ï¸ [ç”Ÿæˆå¯åŠ¨] é¿å¼€åŸè¯ï¼Œæ–°æƒ³æ³• ID: {current_idx}")

        # 4. è·¯å¾„æ¸¸èµ° (Path Walking)
        for _ in range(max_len):
            # è·å–å½“å‰èŠ‚ç‚¹è¿å‘å…¶ä»–èŠ‚ç‚¹çš„æƒé‡
            next_step_weights = self.synapse_matrix[current_idx].clone()

            # A. æ–½åŠ è¿”å›æŠ‘åˆ¶ (Inhibition of Return)
            # èµ°è¿‡çš„è·¯å³ä½¿è¿æ¥å†å¼ºï¼Œä¹Ÿæš‚æ—¶å°æ­»ï¼Œé€¼è¿«å¯»æ‰¾æ–°è·¯
            for v in visited:
                next_step_weights[v] = -float("inf")

            # B. æ–½åŠ æ„å¿µåœºå¼•å¯¼ (Context Guidance)
            # æ··åˆ "å±€éƒ¨è¿æ¥" å’Œ "å…¨å±€è¯­å¢ƒ"
            # 0.5 æ˜¯å¼•å¯¼ç³»æ•°ï¼šæ—¢è¦é¡ºç€è·¯èµ°ï¼Œåˆè¦ä¸å¿˜åˆå¿ƒçš„è¯­å¢ƒ
            guidance = thought_energy[0] * 0.5
            combined_weights = next_step_weights + guidance

            # C. é‡‡æ ·ä¸‹ä¸€ä¸ªè¯
            if torch.max(combined_weights) == -float("inf"):
                break  # æ— è·¯å¯èµ°(æ­»èƒ¡åŒ)

            next_probs = torch.softmax(
                combined_weights * 3.0, dim=0
            )  # Temp=3.0 å¢åŠ ç¡®å®šæ€§
            next_idx = torch.multinomial(next_probs, 1).item()

            reply_indices.append(next_idx)
            visited.add(next_idx)
            current_idx = next_idx

        return reply_indices
