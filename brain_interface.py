import torch
import os
import jieba
import re
from .cognitive_graph_model import CognitiveGraphModel
from .cognitive_trainer import HebbianTrainer


class BrainInterface:
    def __init__(self, model_path="my_brain.pth", vocab_limit=5000):
        self.model_path = model_path
        self.vocab_limit = vocab_limit
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # 1. è¯è¡¨ç®¡ç†
        self.word2idx = {"<PAD>": 0, "<UNK>": 1}
        self.idx2word = {0: "<PAD>", 1: "<UNK>"}
        self.next_idx = 2

        # 2. åˆå§‹åŒ–æ¨¡å‹
        self.model = CognitiveGraphModel(vocab_size=vocab_limit, embed_dim=64).to(self.device)
        self.trainer = HebbianTrainer(self.model, learning_rate=0.1)

        # 3. åŠ è½½å­˜æ¡£
        self.load_brain()

    def load_brain(self):
        if os.path.exists(self.model_path):
            print(f"ğŸ§  æ­£åœ¨å”¤é†’å¤§è„‘: {self.model_path} ...")
            checkpoint = torch.load(self.model_path, map_location=self.device)
            self.model.load_state_dict(checkpoint['model_state'])
            vocab_data = checkpoint['vocab']
            self.word2idx = vocab_data['word2idx']
            self.idx2word = {int(k): v for k, v in vocab_data['idx2word'].items()}
            self.next_idx = vocab_data['next_idx']
            print(f"âœ… å”¤é†’æˆåŠŸã€‚å½“å‰è¯æ±‡é‡: {self.next_idx}/{self.vocab_limit}")
        else:
            print("âœ¨ åˆ›å»ºäº†ä¸€ä¸ªå…¨æ–°çš„å¤§è„‘ã€‚")

    def save_brain(self):
        print("ğŸ’¾ æ­£åœ¨å†™å…¥æµ·é©¬ä½“...")
        state = {
            'model_state': self.model.state_dict(),
            'vocab': {
                'word2idx': self.word2idx,
                'idx2word': self.idx2word,
                'next_idx': self.next_idx
            }
        }
        torch.save(state, self.model_path)
        print("âœ… è®°å¿†å·²å›ºåŒ–ã€‚")

    def trigger_sleep(self):
        """
        [æ–°åŠŸèƒ½] è§¦å‘ç¡çœ æ•´ç†
        """
        print("ğŸ’¤ è¿›å…¥ REM ç¡çœ é˜¶æ®µ (å‹åŠ›é©±åŠ¨ & æ™¶ä½“åŒ–ä¿æŠ¤)...")
        pruned, total, decay = self.model.process_sleep_cycle()
        ratio = pruned / total * 100 if total > 0 else 0
        print(f"âœ¨ ç¡çœ å®Œæˆã€‚æ¸…ç†äº† {pruned} ä¸ªå¾®å¼±çªè§¦ ({ratio:.2f}%)ã€‚å½“å‰è¡°å‡ç³»æ•°: {decay:.3f}")
        self.save_brain()
        return pruned, ratio, decay

    def _clean_text(self, text):
        if not text: return ""
        text_no_cq = re.sub(r'\[CQ:[^\]]+\]', '', text)
        cleaned = re.sub(r'[^\u4e00-\u9fa5]', '', text_no_cq)
        return cleaned

    def _get_or_add_word(self, word):
        """
        è·å–è¯IDï¼Œå¦‚æœä¸å­˜åœ¨ä¸”è¯è¡¨æœªæ»¡åˆ™æ·»åŠ 
        """
        if word in self.word2idx:
            return self.word2idx[word]
        
        if self.next_idx < self.vocab_limit:
            new_id = self.next_idx
            self.word2idx[word] = new_id
            self.idx2word[new_id] = word
            self.next_idx += 1
            return new_id
        
        return self.word2idx["<UNK>"]

    def _encode(self, text):
        clean_text = self._clean_text(text)
        if not clean_text:
            return []

        words = list(jieba.cut(clean_text))
        indices = []

        for w in words:
            if w.strip() == "": continue
            idx = self._get_or_add_word(w)
            indices.append(idx)
        return indices

    def learn(self, text):
        """
        [æ¨¡å¼1] è”æƒ³å­¦ä¹  (å…¼å®¹æ—§æ¥å£)
        """
        indices = self._encode(text)
        if len(indices) < 2: return 0.0
        # è°ƒç”¨ trainer çš„æ–°æ¥å£
        loss = self.trainer.train_step_associative(indices)
        return loss

    def learn_logical(self, triplets):
        """
        [æ¨¡å¼2] é€»è¾‘å­¦ä¹ 
        triplets: list of (head_word, relation, tail_word)
        """
        if not triplets: return 0.0
        
        indices_triplets = []
        for head, rel, tail in triplets:
            # é€»è¾‘å­¦ä¹ å¿…é¡»ç²¾ç¡®ï¼Œæ‰€ä»¥æˆ‘ä»¬è¦ç¡®ä¿æ¦‚å¿µè¿›å…¥è¯è¡¨
            h_idx = self._get_or_add_word(head)
            t_idx = self._get_or_add_word(tail)
            
            if h_idx == 1 or t_idx == 1: # UNK
                # å¦‚æœè¯è¡¨æ»¡äº†å¯¼è‡´å…¨æ˜¯UNKï¼Œé€»è¾‘å°±å­¦ä¸è¿›å»äº†
                continue
                
            indices_triplets.append((h_idx, rel, t_idx))
            
        cnt = self.trainer.train_step_logical(indices_triplets)
        return cnt

    def reply(self, text):
        """
        [Modified] è¿”å› (reply_text, reply_indices)
        """
        indices = self._encode(text)
        if not indices: return "", []

        input_tensor = torch.tensor([indices], device=self.device)
        
        # è°ƒç”¨ Model ç”Ÿæˆ
        out_indices = self.model.generate_reply(input_tensor)
        
        reply_words = [self.idx2word.get(idx, "") for idx in out_indices]
        return "".join(reply_words), out_indices

    def reinforce(self, indices, reward_sign):
        """
        [New!] ä¼ é€’å¥–æƒ©ä¿¡å·ç»™ Model
        """
        if not indices: return
        self.model.reinforce(indices, reward_sign)
